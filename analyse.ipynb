{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4d04a7",
   "metadata": {},
   "source": [
    "# Performance Benchmark: WSI Patch Extraction (Publication-ready)\n",
    "\n",
    "This notebook benchmarks the patch extraction pipeline (`src/preprocessing/extract_patches.py`) on randomly sampled whole-slide images (WSIs).\n",
    "\n",
    "We measure per-slide wall-clock time and relate it to slide size (level-0 pixels), mask size (non-zero ROI pixels), and the number of extracted patches. The benchmark samples 15 valid slides (reproducible seed) and saves both the raw metrics and figures under `outputs/analyse/` for reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e567c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarks for `src/preprocessing/extract_patches.py` - imports and configuration\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Repo functions\n",
    "from src.preprocessing.extract_patches import extract_patches\n",
    "from src.preprocessing.load_wsi import load_wsi\n",
    "from src.preprocessing.xml_to_mask import get_mask\n",
    "from src.preprocessing.annotation_utils import resolve_annotation_path\n",
    "\n",
    "# Configuration - adjust if needed\n",
    "WSI_INDEX = 'outputs/index/wsi_index.csv'\n",
    "OUT_DIR = Path('outputs/analyse')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CSV_OUT = OUT_DIR / 'extract_patches_benchmark.csv'\n",
    "PLOTS_DIR = OUT_DIR\n",
    "N_SAMPLES = 15  # number of random slides to benchmark\n",
    "PATCH_SIZE = 512\n",
    "STRIDE = 512\n",
    "TISSUE_THRESHOLD = 0.2\n",
    "LEVEL = 0\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(f\"Benchmark config: N_SAMPLES={N_SAMPLES}, PATCH_SIZE={PATCH_SIZE}, STRIDE={STRIDE}, LEVEL={LEVEL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b4e7b",
   "metadata": {},
   "source": [
    "## Methods and design\n",
    "\n",
    "- Sample N=15 slides uniformly at random from valid (WSI+annotation) entries in `outputs/index/wsi_index.csv` with a fixed seed for reproducibility.\n",
    "- For each slide:\n",
    "  - Build the ROI mask with `get_mask` and load the WSI via `load_wsi`.\n",
    "  - Time `extract_patches` with `save_dir=None` (measures compute/IO without disk write).\n",
    "  - Record: time_seconds, WSI dimensions (level-0), mask size (non-zero count), and number of extracted patches.\n",
    "- Save a tidy CSV `outputs/analyse/extract_patches_benchmark.csv` for later graphing and a summary CSV with correlations.\n",
    "\n",
    "Configuration below defines patch parameters, level, and sample size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for benchmarking (modular)\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "\n",
    "def _safe_count_nonzero(mask: Optional[np.ndarray]) -> int:\n",
    "    if mask is None:\n",
    "        return 0\n",
    "    return int(np.count_nonzero(mask))\n",
    "\n",
    "\n",
    "def benchmark_slide(wsi_path: str, annotation_path: str,\n",
    "                    patch_size: int = PATCH_SIZE,\n",
    "                    stride: int = STRIDE,\n",
    "                    tissue_threshold: float = TISSUE_THRESHOLD,\n",
    "                    level: int = LEVEL) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Run extract_patches for a single slide and return metrics dict.\n",
    "\n",
    "    Returns None on fatal error.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    try:\n",
    "        if not (wsi_path and os.path.exists(wsi_path)):\n",
    "            metrics['error'] = f'WSI missing: {wsi_path}'\n",
    "            return metrics\n",
    "        if not (annotation_path and os.path.exists(annotation_path)):\n",
    "            metrics['error'] = f'Annotation missing: {annotation_path}'\n",
    "            return metrics\n",
    "\n",
    "        # Build mask\n",
    "        mask = None\n",
    "        try:\n",
    "            mask = get_mask(annotation_path, wsi_path)\n",
    "        except Exception as e:\n",
    "            metrics['error'] = f'get_mask failed: {e}'\n",
    "            return metrics\n",
    "\n",
    "        mask_shape = mask.shape if mask is not None else (0, 0)\n",
    "        mask_nonzero = _safe_count_nonzero(mask)\n",
    "        mask_pixels = int(mask.size) if mask is not None else 0\n",
    "\n",
    "        # Load WSI\n",
    "        try:\n",
    "            wsi = load_wsi(wsi_path)\n",
    "        except Exception as e:\n",
    "            metrics['error'] = f'load_wsi failed: {e}'\n",
    "            return metrics\n",
    "\n",
    "        lvl0_w, lvl0_h = wsi.level_dimensions[0]\n",
    "\n",
    "        # Time extraction without saving to disk (pure read/processing)\n",
    "        t0 = time.perf_counter()\n",
    "        try:\n",
    "            patches = extract_patches(\n",
    "                wsi,\n",
    "                mask=mask,\n",
    "                size=patch_size,\n",
    "                stride=stride,\n",
    "                tissue_threshold=tissue_threshold,\n",
    "                level=level,\n",
    "                save_dir=None,\n",
    "                save_prefix=os.path.splitext(os.path.basename(wsi_path))[0],\n",
    "                save_format='png'\n",
    "            )\n",
    "        finally:\n",
    "            elapsed = time.perf_counter() - t0\n",
    "\n",
    "        num_patches = len(patches) if patches is not None else 0\n",
    "        time_per_patch = elapsed / num_patches if num_patches > 0 else float('nan')\n",
    "\n",
    "        # Approximate grid attempts for context\n",
    "        width_level, height_level = wsi.level_dimensions[level]\n",
    "        grid_x = max(0, (width_level - patch_size) // stride + 1)\n",
    "        grid_y = max(0, (height_level - patch_size) // stride + 1)\n",
    "        approx_grid_attempts = int(grid_x * grid_y)\n",
    "\n",
    "        metrics.update({\n",
    "            'wsi_path': wsi_path,\n",
    "            'annotation_path': annotation_path,\n",
    "            'lvl0_width': int(lvl0_w),\n",
    "            'lvl0_height': int(lvl0_h),\n",
    "            'wsi_pixels': int(lvl0_w) * int(lvl0_h),\n",
    "            'mask_width': int(mask_shape[1]) if mask_shape else 0,\n",
    "            'mask_height': int(mask_shape[0]) if mask_shape else 0,\n",
    "            'mask_pixels': int(mask_pixels),\n",
    "            'mask_nonzero': int(mask_nonzero),\n",
    "            'mask_fraction': float(mask_nonzero) / float(mask_pixels) if mask_pixels>0 else float('nan'),\n",
    "            'patch_size': int(patch_size),\n",
    "            'stride': int(stride),\n",
    "            'num_patches': int(num_patches),\n",
    "            'approx_grid_attempts': int(approx_grid_attempts),\n",
    "            'time_seconds': float(elapsed),\n",
    "            'time_per_patch_s': float(time_per_patch),\n",
    "            'error': None,\n",
    "        })\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch-all to avoid notebook crash; return error in metrics\n",
    "        return {'error': f'benchmark exception: {e}'}\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            if 'wsi' in locals() and hasattr(wsi, 'close'):\n",
    "                wsi.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            del mask\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            del patches\n",
    "        except Exception:\n",
    "            pass\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runner cell: select N random slides and run the benchmark\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "if not os.path.exists(WSI_INDEX):\n",
    "    raise FileNotFoundError(f\"WSI index not found: {WSI_INDEX}\")\n",
    "\n",
    "wsi_df = pd.read_csv(WSI_INDEX)\n",
    "# Filter rows with annotation_path\n",
    "valid_rows = []\n",
    "for _, r in wsi_df.iterrows():\n",
    "    ann = r.get('annotation_path') if 'annotation_path' in r else None\n",
    "    wsi = r.get('wsi_path') if 'wsi_path' in r else None\n",
    "    if not ann or pd.isna(ann):\n",
    "        continue\n",
    "    if not wsi or pd.isna(wsi):\n",
    "        continue\n",
    "    if not os.path.exists(wsi):\n",
    "        continue\n",
    "    if not os.path.exists(ann):\n",
    "        continue\n",
    "    valid_rows.append(r)\n",
    "\n",
    "if len(valid_rows) == 0:\n",
    "    raise RuntimeError('No valid WSI + annotation pairs found in index')\n",
    "\n",
    "sample_size = min(N_SAMPLES, len(valid_rows))\n",
    "sample_rows = random.sample(valid_rows, sample_size)\n",
    "\n",
    "print(f\"Running benchmark on {sample_size} randomly selected slides (seed={RANDOM_SEED})\")\n",
    "\n",
    "collected = []\n",
    "for idx, row in enumerate(sample_rows, start=1):\n",
    "    slide_id = row.get('slide_id') if 'slide_id' in row else os.path.splitext(os.path.basename(str(row.get('wsi_path'))))[0]\n",
    "    print(f\"[{idx}/{sample_size}] Benchmarking: {slide_id}\")\n",
    "    metrics = benchmark_slide(row.get('wsi_path'), row.get('annotation_path'))\n",
    "    if metrics is None:\n",
    "        print(f\"  Skipped {slide_id} due to error\")\n",
    "        continue\n",
    "    metrics['slide_id'] = slide_id\n",
    "    collected.append(metrics)\n",
    "\n",
    "if collected:\n",
    "    df_out = pd.DataFrame(collected)\n",
    "    df_out.to_csv(CSV_OUT, index=False)\n",
    "    print(f\"Saved benchmark CSV to: {CSV_OUT}\")\n",
    "else:\n",
    "    print('No benchmark results collected.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663087ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics and correlations (publication table)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "if not CSV_OUT.exists():\n",
    "    print(f\"CSV not found at {CSV_OUT}. Run the runner cell first.\")\n",
    "else:\n",
    "    df = pd.read_csv(CSV_OUT)\n",
    "    # Ensure numeric types\n",
    "    for c in ['time_seconds', 'wsi_pixels', 'mask_nonzero', 'num_patches']:\n",
    "        df[c] = pd.to_numeric(df.get(c), errors='coerce')\n",
    "\n",
    "    # Basic summary for time per slide\n",
    "    summary = {\n",
    "        'n_slides': int(df.shape[0]),\n",
    "        'time_seconds_mean': float(df['time_seconds'].mean(skipna=True)),\n",
    "        'time_seconds_median': float(df['time_seconds'].median(skipna=True)),\n",
    "        'time_seconds_std': float(df['time_seconds'].std(skipna=True)),\n",
    "        'time_seconds_min': float(df['time_seconds'].min(skipna=True)),\n",
    "        'time_seconds_max': float(df['time_seconds'].max(skipna=True)),\n",
    "    }\n",
    "\n",
    "    # Correlations (Pearson and Spearman) to slide size, mask size, patch count\n",
    "    corr_rows = []\n",
    "    for feat in ['wsi_pixels', 'mask_nonzero', 'num_patches']:\n",
    "        sub = df[[feat, 'time_seconds']].dropna()\n",
    "        if len(sub) >= 2:\n",
    "            r_p, p_p = stats.pearsonr(sub[feat], sub['time_seconds'])\n",
    "            r_s, p_s = stats.spearmanr(sub[feat], sub['time_seconds'])\n",
    "            corr_rows.append({\n",
    "                'feature': feat,\n",
    "                'pearson_r': float(r_p), 'pearson_p': float(p_p),\n",
    "                'spearman_r': float(r_s), 'spearman_p': float(p_s),\n",
    "                'n': int(len(sub))\n",
    "            })\n",
    "        else:\n",
    "            corr_rows.append({\n",
    "                'feature': feat,\n",
    "                'pearson_r': np.nan, 'pearson_p': np.nan,\n",
    "                'spearman_r': np.nan, 'spearman_p': np.nan,\n",
    "                'n': int(len(sub))\n",
    "            })\n",
    "\n",
    "    summary_df = pd.DataFrame([summary])\n",
    "    corr_df = pd.DataFrame(corr_rows)\n",
    "\n",
    "    # Save summary table\n",
    "    summary_path = OUT_DIR / 'extract_patches_benchmark_summary.csv'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write('# summary\\n')\n",
    "    summary_df.to_csv(summary_path, mode='a', index=False)\n",
    "    with open(summary_path, 'a') as f:\n",
    "        f.write('\\n# correlations\\n')\n",
    "    corr_df.to_csv(summary_path, mode='a', index=False)\n",
    "\n",
    "    display(summary_df)\n",
    "    display(corr_df)\n",
    "    print(f\"Saved summary to: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579086de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and visualization cell\n",
    "# Reads the CSV produced by the runner and creates plots saved to disk and displayed inline.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if not CSV_OUT.exists():\n",
    "    print(f\"CSV not found at {CSV_OUT}. Run the runner cell first.\")\n",
    "else:\n",
    "    df = pd.read_csv(CSV_OUT)\n",
    "    # Basic cleaning / type conversions\n",
    "    df['time_seconds'] = pd.to_numeric(df['time_seconds'], errors='coerce')\n",
    "    df['wsi_pixels'] = pd.to_numeric(df['wsi_pixels'], errors='coerce')\n",
    "    df['mask_nonzero'] = pd.to_numeric(df['mask_nonzero'], errors='coerce')\n",
    "    df['num_patches'] = pd.to_numeric(df['num_patches'], errors='coerce')\n",
    "\n",
    "    # Scatter: time vs WSI pixels (log-log)\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    sns.scatterplot(x='wsi_pixels', y='time_seconds', data=df, ax=ax)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('WSI pixels (log)')\n",
    "    ax.set_ylabel('Time (s, log)')\n",
    "    ax.set_title('Extraction time vs WSI size')\n",
    "    out1 = PLOTS_DIR / 'time_vs_wsi_pixels.png'\n",
    "    fig.savefig(out1, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter: time vs mask_nonzero\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    sns.scatterplot(x='mask_nonzero', y='time_seconds', data=df, ax=ax)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Mask non-zero pixels (log)')\n",
    "    ax.set_ylabel('Time (s)')\n",
    "    ax.set_title('Extraction time vs mask size')\n",
    "    out2 = PLOTS_DIR / 'time_vs_mask_nonzero.png'\n",
    "    fig.savefig(out2, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter: time vs num_patches\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    sns.scatterplot(x='num_patches', y='time_seconds', data=df, ax=ax)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Number of extracted patches (log)')\n",
    "    ax.set_ylabel('Time (s)')\n",
    "    ax.set_title('Extraction time vs number of patches')\n",
    "    out3 = PLOTS_DIR / 'time_vs_num_patches.png'\n",
    "    fig.savefig(out3, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Print simple correlations\n",
    "    for c in ['wsi_pixels', 'mask_nonzero', 'num_patches']:\n",
    "        valid = df[[c, 'time_seconds']].dropna()\n",
    "        if len(valid) > 1:\n",
    "            corr = valid[c].corr(valid['time_seconds'])\n",
    "            print(f\"Correlation(time_seconds, {c}) = {corr:.3f}\")\n",
    "        else:\n",
    "            print(f\"Not enough data to compute correlation for {c}\")\n",
    "\n",
    "    print(f\"Saved plots to {PLOTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1630f9a",
   "metadata": {},
   "source": [
    "## Reproducibility and usage\n",
    "\n",
    "- Configure parameters in Cell 2 (imports & configuration). Default: `N_SAMPLES = 15`, `PATCH_SIZE = 512`, `STRIDE = 512`, `LEVEL = 0`, `RANDOM_SEED = 42`.\n",
    "- Run cells in order:\n",
    "  1) Title (informational)\n",
    "  2) Imports & configuration\n",
    "  3) Methods (informational)\n",
    "  4) Helper functions\n",
    "  5) Runner (executes sampling and benchmarking; writes CSV)\n",
    "  6) Summary statistics (saves `extract_patches_benchmark_summary.csv`)\n",
    "  7) Plotting (saves three PNGs)\n",
    "\n",
    "Artifacts (for publication):\n",
    "- Raw metrics CSV: `outputs/analyse/extract_patches_benchmark.csv`\n",
    "- Summary + correlations CSV: `outputs/analyse/extract_patches_benchmark_summary.csv`\n",
    "- Figures: `time_vs_wsi_pixels.png`, `time_vs_mask_nonzero.png`, `time_vs_num_patches.png` in `outputs/analyse/`\n",
    "\n",
    "Environment notes:\n",
    "- Requires WSI IO dependencies (e.g., OpenSlide/cuCIM) compatible with your data and `load_wsi` implementation.\n",
    "- Random sampling is reproducible via `RANDOM_SEED`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "her2-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
