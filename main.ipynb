{
 "cells": [
  {
   "cell_type": "code",
   "id": "d082bcbb9a2eb5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:21:26.229566Z",
     "start_time": "2025-11-19T23:21:19.764100Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import random\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# Additional imports for normalization\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import cupy as cp\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Project imports\n",
    "# -----------------------------------------------------------------------------\n",
    "from src.preprocessing.generate_metadata import discover_wsi\n",
    "from src.preprocessing.xml_to_mask import get_mask\n",
    "from src.preprocessing.annotation_utils import resolve_annotation_path\n",
    "from src.preprocessing.extract_patches import extract_patches\n",
    "from src.preprocessing.load_wsi import load_wsi\n",
    "from src.train.train_phase1 import train_phase1\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Global configuration (single top cell)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Prefer a color-accurate WSI backend for patch extraction\n",
    "# Options: 'openslide' (recommended), 'tiffslide' (good for TIFF/SVS), 'cucim' (fast GPU)\n",
    "os.environ['HER2_WSI_BACKEND'] = os.environ.get('HER2_WSI_BACKEND', 'cucim')\n",
    "print(f\"WSI backend preference: {os.environ['HER2_WSI_BACKEND']}\")\n",
    "\n",
    "# Dataset configuration\n",
    "BASE_DIR = 'data'\n",
    "SOURCES = [\n",
    "    'Yale_HER2_cohort',\n",
    "    'Yale_trastuzumab_response_cohort',\n",
    "    'TCGA_BRCA_Filtered',\n",
    "]\n",
    "OUTPUT_CSV = 'outputs/index/wsi_index.csv'\n",
    "\n",
    "# Patch extraction configuration\n",
    "PATCH_SIZE = 512\n",
    "PATCH_STRIDE = 512\n",
    "PATCH_SAVE_FORMAT = 'png'  # e.g., 'png' or 'jpg'\n",
    "\n",
    "# Normalization configuration\n",
    "# - NORM_INPLACE: if True, overwrite original patch files; else, write to NORM_OUTPUT_DIR mirroring structure\n",
    "# - NORM_OUTPUT_DIR: target directory for normalized patches when not in-place (can be an absolute path to an external drive)\n",
    "# - USE_NORMALIZED_FOR_TRAINING: if True and normalized CSV exists, use it in training\n",
    "NORM_INPLACE = False\n",
    "# prefer an env var named NORM_OUTPUT_DIR; fallback to a reasonable external path or local outputs folder\n",
    "NORM_OUTPUT_DIR = os.environ.get('NORM_OUTPUT_DIR', '/media/thanakornbuath/patch/norm')\n",
    "USE_NORMALIZED_FOR_TRAINING = False\n",
    "# Number of distinct subfolders (cases) to sample to compute the reference stain profile\n",
    "NORM_REFERENCE_SAMPLE_SUBFOLDERS = 40\n",
    "# Use GPU for stain normalization numeric work (requires CuPy and GPU drivers). Set False to force CPU.\n",
    "USE_GPU = True\n",
    "\n",
    "# Optional: path to CSV column name that contains image path; leave None to auto-detect\n",
    "CSV_PATH_COLUMN = None\n",
    "# File extensions to consider (lowercase)\n",
    "IMAGE_EXTS = {'.png', '.jpg', '.jpeg', '.tif', '.tiff'}\n",
    "# Safety: chunk size when listing/processing very large CSVs (tweak if needed)\n",
    "CHUNK_SIZE = 2000\n",
    "\n",
    "# Logging configuration\n",
    "log_dir = 'outputs/preprocessing/logs'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_path = os.path.join(log_dir, 'preprocessing.log')\n",
    "\n",
    "def log(msg: str):\n",
    "    print(msg)\n",
    "    try:\n",
    "        with open(log_path, 'a') as f:\n",
    "            f.write(msg + '\\n')\n",
    "    except Exception:\n",
    "        # Fallback to console if file logging fails\n",
    "        pass\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSI backend preference: cucim\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "80b380fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:21:26.343221Z",
     "start_time": "2025-11-19T23:21:26.243919Z"
    }
   },
   "source": [
    "# Discover WSIs and build index CSV\n",
    "csv_path = discover_wsi(\n",
    "    base_dir=BASE_DIR,\n",
    "    sources=SOURCES,\n",
    "    output_path=OUTPUT_CSV,\n",
    ")\n",
    "\n",
    "# Load and display the results\n",
    "df = pd.read_csv(csv_path)\n",
    "display(df.head(5))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sources:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Processing Yale_HER2_cohort:   0%|          | 0/192 [00:00<?, ?it/s]\u001B[A\n",
      "                                                                    \u001B[A\n",
      "Processing Yale_trastuzumab_response_cohort:   0%|          | 0/85 [00:00<?, ?it/s]\u001B[A\n",
      "                                                                                   \u001B[A\n",
      "Processing TCGA_BRCA_Filtered:   0%|          | 0/182 [00:00<?, ?it/s]\u001B[A\n",
      "Processing sources: 100%|██████████| 3/3 [00:00<00:00, 88.55it/s]     \u001B[A\n",
      "                                                         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                        wsi_path         slide_id  \\\n",
       "0  data/Yale_HER2_cohort/SVS/Her2Neg_Case_01.svs  Her2Neg_Case_01   \n",
       "1  data/Yale_HER2_cohort/SVS/Her2Neg_Case_02.svs  Her2Neg_Case_02   \n",
       "2  data/Yale_HER2_cohort/SVS/Her2Neg_Case_03.svs  Her2Neg_Case_03   \n",
       "3  data/Yale_HER2_cohort/SVS/Her2Neg_Case_04.svs  Her2Neg_Case_04   \n",
       "4  data/Yale_HER2_cohort/SVS/Her2Neg_Case_05.svs  Her2Neg_Case_05   \n",
       "\n",
       "            slide_name      annotation_name  \\\n",
       "0  Her2Neg_Case_01.svs  Her2Neg_Case_01.xml   \n",
       "1  Her2Neg_Case_02.svs  Her2Neg_Case_02.xml   \n",
       "2  Her2Neg_Case_03.svs  Her2Neg_Case_03.xml   \n",
       "3  Her2Neg_Case_04.svs  Her2Neg_Case_04.xml   \n",
       "4  Her2Neg_Case_05.svs  Her2Neg_Case_05.xml   \n",
       "\n",
       "                                     annotation_path  \n",
       "0  data/Yale_HER2_cohort/Annotations/Her2Neg_Case...  \n",
       "1  data/Yale_HER2_cohort/Annotations/Her2Neg_Case...  \n",
       "2  data/Yale_HER2_cohort/Annotations/Her2Neg_Case...  \n",
       "3  data/Yale_HER2_cohort/Annotations/Her2Neg_Case...  \n",
       "4  data/Yale_HER2_cohort/Annotations/Her2Neg_Case...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wsi_path</th>\n",
       "      <th>slide_id</th>\n",
       "      <th>slide_name</th>\n",
       "      <th>annotation_name</th>\n",
       "      <th>annotation_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/Yale_HER2_cohort/SVS/Her2Neg_Case_01.svs</td>\n",
       "      <td>Her2Neg_Case_01</td>\n",
       "      <td>Her2Neg_Case_01.svs</td>\n",
       "      <td>Her2Neg_Case_01.xml</td>\n",
       "      <td>data/Yale_HER2_cohort/Annotations/Her2Neg_Case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/Yale_HER2_cohort/SVS/Her2Neg_Case_02.svs</td>\n",
       "      <td>Her2Neg_Case_02</td>\n",
       "      <td>Her2Neg_Case_02.svs</td>\n",
       "      <td>Her2Neg_Case_02.xml</td>\n",
       "      <td>data/Yale_HER2_cohort/Annotations/Her2Neg_Case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/Yale_HER2_cohort/SVS/Her2Neg_Case_03.svs</td>\n",
       "      <td>Her2Neg_Case_03</td>\n",
       "      <td>Her2Neg_Case_03.svs</td>\n",
       "      <td>Her2Neg_Case_03.xml</td>\n",
       "      <td>data/Yale_HER2_cohort/Annotations/Her2Neg_Case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/Yale_HER2_cohort/SVS/Her2Neg_Case_04.svs</td>\n",
       "      <td>Her2Neg_Case_04</td>\n",
       "      <td>Her2Neg_Case_04.svs</td>\n",
       "      <td>Her2Neg_Case_04.xml</td>\n",
       "      <td>data/Yale_HER2_cohort/Annotations/Her2Neg_Case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/Yale_HER2_cohort/SVS/Her2Neg_Case_05.svs</td>\n",
       "      <td>Her2Neg_Case_05</td>\n",
       "      <td>Her2Neg_Case_05.svs</td>\n",
       "      <td>Her2Neg_Case_05.xml</td>\n",
       "      <td>data/Yale_HER2_cohort/Annotations/Her2Neg_Case...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3855ee62",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-11-19T23:21:30.533353Z",
     "start_time": "2025-11-19T23:21:30.099879Z"
    }
   },
   "source": [
    "# Extract patches for each slide\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc='Processing slides'):\n",
    "    wsi_path = row['wsi_path']\n",
    "    wsi_path = str(wsi_path)  # ensure path-like string to satisfy os.path methods\n",
    "\n",
    "    # Define patch output directory to check if it's already processed\n",
    "    slide_base = os.path.splitext(os.path.basename(wsi_path))[0]\n",
    "    out_dir_patches = os.path.join('outputs', 'patches', slide_base)\n",
    "\n",
    "    # --- Skip if patches already exist ---\n",
    "    if os.path.isdir(out_dir_patches) and len(os.listdir(out_dir_patches)) > 0:\n",
    "        log(f\"Skipping already extracted slide: {wsi_path}\")\n",
    "        continue\n",
    "\n",
    "    # Resolve annotation path using helper (handles pandas NA, relative paths, and glob fallback)\n",
    "    annotation_path = resolve_annotation_path(row.get('annotation_path', None), wsi_path, base_dir=BASE_DIR)\n",
    "    if not annotation_path:\n",
    "        log(f\"Skipping slide without annotation: {wsi_path}\")\n",
    "        continue\n",
    "\n",
    "    log(f\"Processing slide: {wsi_path} with annotation: {annotation_path}\")\n",
    "    try:\n",
    "        mask = get_mask(annotation_path, wsi_path)\n",
    "    except Exception as e:\n",
    "        log(f\"Failed to generate mask for {wsi_path}: {e}\")\n",
    "        continue\n",
    "    if mask is None:\n",
    "        log(f\"No mask generated for {wsi_path}\")\n",
    "        continue\n",
    "\n",
    "    # At this point mask should be a 2D uint8 array (0 or 255)\n",
    "    log(f'Mask shape: {mask.shape}')\n",
    "\n",
    "    # Load WSI\n",
    "    try:\n",
    "        wsi_slide = load_wsi(wsi_path)\n",
    "    except Exception as e:\n",
    "        log(f\"Failed to load WSI ({wsi_path}): {e}\")\n",
    "        continue\n",
    "    if wsi_slide is None:\n",
    "        log(f\"Failed to load WSI: {wsi_path}\")\n",
    "        continue\n",
    "\n",
    "    # Log which backend the loader selected\n",
    "    backend = getattr(wsi_slide, 'backend', 'unknown')\n",
    "    log(f'Loaded WSI backend: {backend}')\n",
    "\n",
    "    # Determine if we should use GPU for patch extraction\n",
    "    use_gpu_extraction = (backend == 'cucim')\n",
    "    if use_gpu_extraction:\n",
    "        log(f'Enabling GPU-accelerated patch extraction for {wsi_path}')\n",
    "\n",
    "    # Extract patches\n",
    "    try:\n",
    "        patches = extract_patches(\n",
    "            wsi_slide,\n",
    "            mask=mask,\n",
    "            size=PATCH_SIZE,\n",
    "            stride=PATCH_STRIDE,\n",
    "            save_dir=out_dir_patches,\n",
    "            save_prefix=slide_base,\n",
    "            save_format=PATCH_SAVE_FORMAT,\n",
    "            use_gpu=use_gpu_extraction,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        log(f\"Failed to extract patches for {wsi_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    saved = sum(1 for p in patches if p.get('path'))\n",
    "    log(f'Extracted {len(patches)} patches from {wsi_path}; saved {saved} to {out_dir_patches}')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing slides:  72%|███████▏  | 330/459 [00:00<00:00, 3261.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_01.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_02.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_03.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_04.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_05.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_06.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_07.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_08.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_09.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_10.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_11.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_12.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_13.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_14.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_15.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_16.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_17.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_18.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_19.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_20.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_21.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_22.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_23.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_24.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_25.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_26.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_27.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_28.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_29.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_30.svs\n",
      "Skipping slide without annotation: data/Yale_HER2_cohort/SVS/Her2Neg_Case_31.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_32.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_33.svs\n",
      "Skipping slide without annotation: data/Yale_HER2_cohort/SVS/Her2Neg_Case_34.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_35.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_36.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_37.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_38.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_39.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_40.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_41.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_42.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_43.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_44.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_45.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_46.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_47.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_48.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_49.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_50.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_51.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_52.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_53.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_54.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_55.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_56.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_57.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_58.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_59.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_60.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_61.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_62.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_63.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_64.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_65.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_66.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_67.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_68.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_69.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_70.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_71.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_72.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_73.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_74.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_75.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_76.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_77.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_78.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_79.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_80.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_81.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_82.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_83.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_84.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_85.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_86.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_87.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_88.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_89.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_90.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_91.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_92.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_93.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_94.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_95.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_96.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_97.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_98.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Neg_Case_99.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_01.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_02.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_03.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_04.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_05.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_06.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_07.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_08.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_09.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_10.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_11.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_12.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_13.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_14.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_15.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_16.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_17.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_18.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_19.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_20.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_21.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_23.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_24.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_25.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_26.svs\n",
      "Skipping slide without annotation: data/Yale_HER2_cohort/SVS/Her2Pos_Case_27.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_28.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_29.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_30.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_31.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_32.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_33.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_34.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_35.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_36.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_37.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_38.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_39.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_40.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_41.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_42.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_43.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_44.svs\n",
      "Skipping slide without annotation: data/Yale_HER2_cohort/SVS/Her2Pos_Case_45.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_46.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_47.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_48.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_49.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_50.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_51.svs\n",
      "Skipping slide without annotation: data/Yale_HER2_cohort/SVS/Her2Pos_Case_52.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_53.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_54.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_55.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_56.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_57.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_58.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_59.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_60.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_61.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_62.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_63.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_64.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_65.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_66.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_67.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_68.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_69.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_70.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_71.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_72.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_73.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_74.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_75.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_76.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_77.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_78.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_79.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_80.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_81.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_82.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_83.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_84.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_85.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_86.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_87.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_88.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_89.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_90.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_91.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_92.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_93.svs\n",
      "Skipping already extracted slide: data/Yale_HER2_cohort/SVS/Her2Pos_Case_94.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/O09-03495.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/O10-12717.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/O14-02301.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/O16-11870.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/O16-18464.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/O17-01529.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/O18-12772.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S08-31466.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S09-15833.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S09-19750.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S10-00647.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S10-09633.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S11-15267.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S11-24835.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S12-07776.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S12-22754.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S12-28303.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S12-35886.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S13-07627.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S13-08586.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S13-11381.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S13-15979.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S13-31494.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S13-33035.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-01774.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-04504.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-12226.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-12770.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-12928.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-13440.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-13994.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-15197.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S14-16118.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-00942.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-02790.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-03056.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-05781.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-05979.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-06857.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-10140.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-12411.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-12838.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-13623.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-14834.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-15318.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-20350.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-27036.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S15-28568.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-00356.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-01567.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-06544.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-08071.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-11632.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-12501.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-19596.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-20727.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-23506.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-28041.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-28729.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-29941.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-30001.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-30545.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S16-32975.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S17-00215.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S17-00970.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S17-08236.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S17-08865.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S17-08918.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S17-14190.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S17-14334.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S17-20728.svs\n",
      "Processing slide: data/Yale_trastuzumab_response_cohort/SVS/S17-22163.svs with annotation: /media/thanakornbuath/data SSD/her2-attention-classifier/data/Yale_trastuzumab_response_cohort/Annotations/S17-22163.xml\n",
      "Failed to generate mask for data/Yale_trastuzumab_response_cohort/SVS/S17-22163.svs: junk after document element: line 3, column 1\n",
      "Processing slide: data/Yale_trastuzumab_response_cohort/SVS/S18-03825.svs with annotation: /media/thanakornbuath/data SSD/her2-attention-classifier/data/Yale_trastuzumab_response_cohort/Annotations/S18-03825.xml\n",
      "Failed to generate mask for data/Yale_trastuzumab_response_cohort/SVS/S18-03825.svs: junk after document element: line 3, column 1\n",
      "Processing slide: data/Yale_trastuzumab_response_cohort/SVS/S18-03934.svs with annotation: /media/thanakornbuath/data SSD/her2-attention-classifier/data/Yale_trastuzumab_response_cohort/Annotations/S18-03934.xml\n",
      "Failed to generate mask for data/Yale_trastuzumab_response_cohort/SVS/S18-03934.svs: junk after document element: line 3, column 1\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-05363.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-09519.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-10074.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-12553.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-15441.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-18704.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-25097.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-27506.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-30424.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-31022.svs\n",
      "Skipping already extracted slide: data/Yale_trastuzumab_response_cohort/SVS/S18-32412.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A1-A0SP-01Z-00-DX1.20D689C6-EFA5-4694-BE76-24475A89ACC0.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A04W-01Z-00-DX1.F7E7B945-2ADC-4741-8FCE-ACEA657DB9C7.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A04X-01Z-00-DX1.E01A4522-67B3-4FEF-BD6B-99DFED9E7C85.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A0CX-01Z-00-DX1.F07C75AB-E568-45CB-B497-37C712490393.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A0EY-01Z-00-DX1.2F2428B3-0767-48E0-AC22-443C244CBD16.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A0SW-01Z-00-DX1.E1EA0407-B831-4D75-826E-80B82B821797.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A0SY-01Z-00-DX1.279A5479-E183-4F79-AF40-50BF1834BA4A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A0YG-01Z-00-DX1.89A39319-F880-47DE-B311-DA1F6A64B6F3.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A0YL-01Z-00-DX1.69A438C7-B1E0-4990-B1E6-586C551DC79C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A1G1-01Z-00-DX1.E52A474F-DE13-41CF-94D4-D00BAC46ECF4.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A2-A259-01Z-00-DX1.7289CD72-CB74-41D4-B4AC-4EA5FDFEC666.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A7-A0CG-01Z-00-DX1.D77019C2-96B1-4EF5-A61E-5F2D5B8D9852.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A7-A0CJ-01Z-00-DX1.E26F2F62-D688-4373-BB7B-790A06734E49.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A7-A0D9-01Z-00-DX1.FBC3B90F-C58B-4476-8354-0AF9248324E3.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A7-A26H-01Z-00-DX1.3344CFD3-5A19-4B01-BEB2-AB89F83FD53A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A7-A26I-01Z-00-DX1.0077D012-BC14-4E96-84F7-A1A6A3A778DF.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A075-01Z-00-DX1.8E06AF51-951F-48E8-934E-42A455F65E5F.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A076-01Z-00-DX1.BAAC4F9C-0C04-42FB-95F4-D765305089B8.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A07B-01Z-00-DX1.950B5E4E-C5F0-4445-9F88-E8C32CDFE6DA.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A07E-01Z-00-DX1.AC684481-979A-46F9-91D7-C56CE85992F2.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A07I-01Z-00-DX1.37E7BB2E-8210-4216-B75F-0FD06D6C9AE3.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A07P-01Z-00-DX1.2C7C75EF-EEE2-4A42-994C-A1A40850C87A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A07U-01Z-00-DX1.69D356C3-C7FC-47E9-B753-BE421263343F.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A08B-01Z-00-DX1.416316FD-E8BF-402C-939A-08920F08A181.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A08G-01Z-00-DX1.C3BB7FEC-91B7-4B45-8DFC-36CABCC0FD57.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A08P-01Z-00-DX1.431A1290-9CF4-4CE7-A9F0-13F9ADA46ADA.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A08S-01Z-00-DX1.C0E044C2-FC3F-4E3D-A779-A725FF375F21.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A08X-01Z-00-DX1.01FB49CC-6B8E-4317-8C42-6B6D81187A40.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A094-01Z-00-DX1.6750B72A-FEC7-49FA-8520-FCF101CA59AC.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A095-01Z-00-DX1.97072E53-7323-4836-9D58-22B7C346A7CE.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A097-01Z-00-DX1.4D06990E-E759-40F0-9106-59408CF350E5.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A099-01Z-00-DX1.B19C28B5-FEBC-49B4-A60E-E6B85BB00DD7.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A09D-01Z-00-DX1.66312A8A-88BA-4B58-96DF-1A7AC39F9E4A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A09G-01Z-00-DX1.B834728C-DAC5-4463-961D-7E3B220905C1.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A09I-01Z-00-DX1.B738E479-8766-4766-B012-B32AC2F27533.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A09K-01Z-00-DX1.41B2DF5F-C0E1-43BB-BAA5-2946A9EC4650.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A09X-01Z-00-DX1.17B5BE28-944F-427B-8F90-44885C3EDD36.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-A8-A0A2-01Z-00-DX1.47BCDF13-1065-466A-B7CB-F91F5EAD7D91.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AC-A23C-01Z-00-DX1.0E67C785-83D3-49AF-B600-FB5B909AE6ED.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AC-A23H-01Z-00-DX1.8E0AE339-1047-4CA5-BFC5-37A3B10FD8B5.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A046-01Z-00-DX1.C529B94F-AFE3-4701-BC98-5D6EDF7B82C0.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0AJ-01Z-00-DX1.74EE47B0-FE27-44CF-9355-C738DE1BD017.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0AL-01Z-00-DX1.D9E446A3-175F-4242-AFC1-78FFE3FC9AC4.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0AM-01Z-00-DX1.169CE39A-DD54-46D8-8D03-60B69A473CDB.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0FJ-01Z-00-DX1.97B60767-916E-4938-9D0B-E6C0FE1CB3FC.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0FL-01Z-00-DX1.20A041C6-A306-4599-A7D1-65032A252AA9.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0FT-01Z-00-DX1.6F263AB3-FB1D-4056-AEC2-4F163017324F.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0FV-01Z-00-DX1.C0D02946-FCDA-472D-895D-7ACF5C96B264.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0FW-01Z-00-DX1.5EEDFC71-6ABE-4189-8C45-2127403A8F04.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AN-A0XT-01Z-00-DX1.882AF4CE-62A1-4808-9B4B-780066E5E602.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AO-A03V-01Z-00-DX1.52EBCB72-0C65-4E67-B9BB-DA15494327DE.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AO-A0J5-01Z-00-DX1.20C14D0C-1A74-4FE9-A5E6-BDDCB8DE7714.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AO-A0JD-01Z-00-DX1.52E3DCE8-32E3-45C0-AB54-7FA0A2F3F722.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AO-A0JE-01Z-00-DX1.82D33053-E305-47D8-9B02-B55511EBB06D.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AO-A0JJ-01Z-00-DX1.D5B636F5-1B47-4033-9938-9DC8CD48CEE9.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AO-A0JM-01Z-00-DX1.94E75EFD-E5F5-4DF8-93A0-ED94CB4D203A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AO-A129-01Z-00-DX1.BF485416-BF57-4F39-866B-4B1E201876FA.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AO-A12D-01Z-00-DX1.BA006BAD-5C6E-4099-BC99-3888E69F506E.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AQ-A04H-01Z-00-DX1.5AC1E459-EF27-401D-98FD-0AC16559AF17.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AQ-A04L-01Z-00-DX1.F35BF4DD-896A-43C2-8DA6-C67945C003BE.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AQ-A0Y5-01Z-00-DX1.f68f5b49-30fa-4fb6-bec6-5da9f6809d02.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A0TP-01Z-00-DX1.58E6A3A6-D1D7-4AE5-87A5-E823F04CBB2F.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A0TQ-01Z-00-DX1.2BEA298C-6B3D-4133-ADBC-769E62CEFFA0.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A0TX-01Z-00-DX1.5BEA4E65-8CEC-49B2-9F29-DBE53E8ED46E.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A0TY-01Z-00-DX1.089EB6B4-9921-441D-84F3-C64C97AFC3B4.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A0U3-01Z-00-DX1.9BB87F9D-459F-4A18-B591-29822EA5AE18.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A0U4-01Z-00-DX1.DE722DC5-859D-4866-ADCC-ED98EDBFB588.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A1AH-01Z-00-DX1.5D5D7774-77BB-4EA0-9E8E-A8D28F70A575.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A1AN-01Z-00-DX1.1118F9FE-6DF2-4496-B102-D3A10D332EC0.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A1AQ-01Z-00-DX1.09D5D7FC-0FA8-4176-94B2-995F44D8ED4C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A1AR-01Z-00-DX1.E7B7F6F0-9CC0-4D4F-8C9F-443A74D2BE40.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A1AX-01Z-00-DX1.2389D54F-545E-499E-B392-DD731834460A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A1AY-01Z-00-DX1.6AC0BE3B-FFC5-4EDA-9E40-B18CAAC52B81.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A24Q-01Z-00-DX1.69DC7E35-DC0D-4F20-88DA-04C25F28628C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A24U-01Z-00-DX1.220FD0D0-0DB6-4E3C-92A0-66CD6509F0AD.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A250-01Z-00-DX1.572A2F73-6BF5-4932-BFEF-4B8904755ACF.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A254-01Z-00-DX1.EA5CD008-1106-41EC-998A-04EF08EEEC9D.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-AR-A255-01Z-00-DX1.E67C081D-50C9-451C-814B-F097B2671300.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-B6-A0IH-01Z-00-DX1.3463B12E-D1B0-4FB2-B257-BFD63BA2B6BF.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-B6-A0IK-01Z-00-DX1.1640DB44-4AC0-4A34-9E21-4673C4289A99.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-B6-A0RH-01Z-00-DX1.33DB5CF9-AC87-435B-A8AF-C4F84BEF15F1.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-B6-A0RV-01Z-00-DX1.C46C2937-868D-47B7-B9B9-E51F5433BE97.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-B6-A0WV-01Z-00-DX1.A8B9E114-A8CF-4389-B47C-2E1B842F7FF9.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-B6-A1KF-01Z-00-DX1.2E08E830-4216-4CD0-9646-1F489300E11D.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-B6-A1KN-01Z-00-DX1.E769FD65-E5CE-4CA4-8BBE-6FC54A2ED870.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0AW-01Z-00-DX1.9D50A0D2-B103-411C-831E-8520C3D50173.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0B0-01Z-00-DX1.316D35DB-7F13-4AE5-82A7-5716D2519669.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0B4-01Z-00-DX1.A2CB0BF4-32F9-48FD-9B96-A744013BADDB.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0B9-01Z-00-DX1.C23ADB4C-52D4-4DFD-B8E3-156E43F0E645.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0BA-01Z-00-DX1.579E11C9-437C-4D49-8811-DD94D8454712.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0BC-01Z-00-DX1.7A91831D-9625-49FC-B783-C633F80F898C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0BF-01Z-00-DX1.934DF984-9054-4B20-B85B-9CF94B8DC3D4.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0BP-01Z-00-DX1.63A87C1D-87FA-494D-9836-74290B5DC30D.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0BR-01Z-00-DX1.F7912887-8AE9-4391-9B83-9AC7B4FF38EF.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0C0-01Z-00-DX1.2D32D35A-EB7E-4D0E-BE5F-E56F7B930463.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0C7-01Z-00-DX1.C70D358E-C48F-4F69-86CE-3218E9C95837.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0DD-01Z-00-DX1.2242DD1F-0B7C-4B43-A7A9-8130D2BDEE78.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0DG-01Z-00-DX1.D3C4F57F-608F-46AA-A978-B558117C9DFB.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0DK-01Z-00-DX1.0CFED53C-BAD9-4E35-B12F-57E64F3FEF1C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0DZ-01Z-00-DX1.138BAEC2-589E-4960-B94E-DF48DDAA5490.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0E2-01Z-00-DX1.5F6FA19C-D59F-45BE-80CE-F738CAB1EF0B.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0EE-01Z-00-DX1.872EA586-25C8-4835-A138-152DFA1EBF30.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0HB-01Z-00-DX1.F90F7139-B804-4548-9FAF-9B475BF225EB.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A0HP-01Z-00-DX1.F1FF6E88-B2D1-40AA-8373-1714D82E666F.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A18F-01Z-00-DX1.81A81589-2D77-4CD6-BD34-76E292AA031D.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A18J-01Z-00-DX1.AE20ADB6-050C-405D-BF17-1EE4A1A4979A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A18R-01Z-00-DX1.07E6FA7F-5072-4327-9982-A40F010B7532.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A18U-01Z-00-DX1.63940315-59BC-462B-87A8-2BBB33C9503E.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A1EN-01Z-00-DX1.F535657F-E2FA-4283-87AE-7DAB663B196B.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A1EY-01Z-00-DX1.25C3DE1F-C702-4959-8DFA-69EF78AD9307.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-BH-A1F2-01Z-00-DX1.17E2FD6F-0DCF-425B-864B-21ADCDAE734B.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A12K-01Z-00-DX1.D71C7974-65F7-4EF0-8FFB-9F27CEC85242.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A12L-01Z-00-DX1.01863BE4-F4AB-45DE-894A-46544777C519.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A12P-01Z-00-DX1.670B5DE8-07B0-4E4C-93FA-FA3DFFCCE50D.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A12Q-01Z-00-DX1.CE74E5B7-FD30-4CBE-8716-ECCF2213AAC3.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A12T-01Z-00-DX1.EF628C26-C570-4D15-A0C0-58B2CC40ABFC.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A12Z-01Z-00-DX1.22616420-7C80-42DE-9C44-0F00327681C6.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A132-01Z-00-DX1.6CCE1FE0-BB4B-4046-BAF0-43AA110B2EBE.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A134-01Z-00-DX1.78D10BCC-98B3-4587-897D-3E27DA28D2EB.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A135-01Z-00-DX1.B69A605E-B577-4F43-9471-2C95312B05D9.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A137-01Z-00-DX1.87F3775D-A401-4D5E-843F-8FB1D4BE97F8.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A138-01Z-00-DX1.845A0680-23A4-4A58-A9C4-2EE17BDBD371.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A1HF-01Z-00-DX1.81EF9A57-54E1-4750-9816-5571FD18A297.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A1HJ-01Z-00-DX1.745159F1-85E7-4CC0-B088-E1CA91916FB8.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A1HK-01Z-00-DX1.A15F452B-1260-4106-86D1-05F00082F0CE.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A1HL-01Z-00-DX1.CC21CAE9-DE48-4ADE-A959-5A99010AAFAC.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A1HO-01Z-00-DX1.0C702CEE-C373-4D00-A706-32206D41AC17.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A26V-01Z-00-DX1.6E86DF74-D575-4969-8142-963D9DF5208F.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A26W-01Z-00-DX1.CFF07941-6CD1-4CF9-BE5F-387DA67B66CC.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A273-01Z-00-DX1.6E5D581F-DF80-478D-82D1-6D6525EED1B5.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A275-01Z-00-DX1.44D27E67-4DD6-4893-B38A-01E48F5A358A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-C8-A278-01Z-00-DX1.188B3FE0-7B20-401A-A6B7-8F1798018162.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A13Y-01Z-00-DX1.02321E77-A11E-41A5-95FE-BB897EA5CE58.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A13Z-01Z-00-DX1.517140BB-D34C-42F8-952C-340EF16D382F.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A140-01Z-00-DX1.5B9382C0-332C-4FBF-82CD-B9453D02B815.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1J9-01Z-00-DX1.F81FA9EF-8129-4E17-A9AD-2B850782CC18.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1JA-01Z-00-DX1.BD43F94A-D5A8-490E-AED4-5F3AB24080FA.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1JB-01Z-00-DX1.6CF48257-066C-4B8C-91AA-30A6B4AD4307.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1JN-01Z-00-DX1.3B02989C-CEA0-4EDD-A6DC-21C3A957C640.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1X5-01Z-00-DX1.81B10B43-0D99-44D0-A245-D652041B8FEE.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1XJ-01Z-00-DX1.660DDF8D-6816-4EBE-AF37-6F7A374F4E9E.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1XK-01Z-00-DX1.41EB1BBC-F230-4E3F-8C4E-CE331CAF1935.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1XS-01Z-00-DX1.E5C78E5A-947C-499D-9E95-619FEEC63E69.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1XT-01Z-00-DX1.9E4DEEEB-AB0A-45F6-A69B-65B3E6F22D46.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1XY-01Z-00-DX1.AC051FB4-1D51-449B-BF2D-9DDB4382414C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A1XZ-01Z-00-DX1.8E51A61D-B01C-4A52-8F5D-44D2ABCA46FC.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A27F-01Z-00-DX1.C1A87F27-49F1-46BA-B2E2-A89293F7FD0C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A27H-01Z-00-DX1.BE9DFDD4-97C5-4327-B1DA-4B34A6F267C5.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A27M-01Z-00-DX1.3020D223-2400-4A2D-8BFE-08A5B78FE13B.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A27N-01Z-00-DX1.85613A4F-1FFB-4091-B925-8E8A7C7A6D95.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-D8-A27W-01Z-00-DX1.CE2D4FEA-284C-44AF-A70F-7956D91CCB29.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A14P-01Z-00-DX1.663B02FF-C64B-41A6-8685-FD61CD76F9C6.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A14Q-01Z-00-DX1.C19BA7FD-D986-4E3B-9A79-F3531A78F05D.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A14V-01Z-00-DX1.D6274B5E-644C-478C-817F-B8BB9262D6F4.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A14W-01Z-00-DX1.2AF665A9-F582-4C41-B2B8-1982648CDEC7.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A14Y-01Z-00-DX1.804A22A3-FD8D-4C8A-A766-48D28434DE22.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A14Z-01Z-00-DX1.A1344A78-1842-4578-8CDE-921E50656891.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A152-01Z-00-DX1.B0860DEB-D34B-4C5D-97F5-C1C646437424.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A158-01Z-00-DX1.994C60FE-E651-4224-95E7-4669834F2338.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A15H-01Z-00-DX1.E3A9DFDC-204D-4F03-98D9-97BBBB74E840.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A15M-01Z-00-DX1.6E4671E5-18EA-4464-BE7C-C94767136E5C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A1B0-01Z-00-DX1.4C50EC91-A62A-450E-88C0-7DCAB8E9724C.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A1B5-01Z-00-DX1.AB19FF3D-5C42-4D49-ABEA-D2315709B6EA.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A1II-01Z-00-DX1.7F782477-0F92-4C57-8735-A1E3F95A6B94.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A1L7-01Z-00-DX1.BE796CD2-2E81-44E8-8CA2-85B4D2A31B64.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E2-A1LB-01Z-00-DX1.B4AFDB08-BA09-4F6E-806E-4054B790AB8E.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A1N5-01Z-00-DX1.94DE7B4B-3798-4CC2-8A64-77796A58821A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A1NA-01Z-00-DX1.2A2FE8BB-621E-43A2-8449-F8FE730C0487.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A1RB-01Z-00-DX1.845074ea-43bc-4752-9dc0-fca72d2ab5de.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A226-01Z-00-DX1.14f1f4c7-4e6e-4574-af20-60d2ab511b2a.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A228-01Z-00-DX1.adbeed20-3b14-44fe-a98a-3bf7cecea30a.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A22A-01Z-00-DX1.d986c9eb-2c54-4663-a54b-04c0756db6db.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A22D-01Z-00-DX1.b2867437-0add-4b7d-8002-fb09ed961942.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A22G-01Z-00-DX1.2b47e321-7910-40ec-ad1c-c4e08ed26334.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-E9-A249-01Z-00-DX1.CA244384-FD89-44F6-8F94-A060A4C241CA.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-EW-A1IW-01Z-00-DX1.0DE87057-951F-4887-A2D5-485736D66E4E.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-EW-A1J3-01Z-00-DX1.F736F6F4-0859-439A-A417-98B520C8D65A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-EW-A1P4-01Z-00-DX1.3E9AE553-83D4-4B09-AB7F-D096BCE3BC4D.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-EW-A1P8-01Z-00-DX1.E9852193-8CDD-49EF-B49B-DA6931198F0D.svs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing slides: 100%|██████████| 459/459 [00:00<00:00, 1126.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-EW-A1PA-01Z-00-DX1.03B033F8-62C0-49E1-BDEA-C5217AB3460A.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-EW-A1PD-01Z-00-DX1.6F6A0122-A50B-4D00-9A3F-7A2502D44E38.svs\n",
      "Skipping already extracted slide: data/TCGA_BRCA_Filtered/SVS/TCGA-EW-A1PF-01Z-00-DX1.9420D058-65CE-4DF8-815F-EB407003096E.svs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "088cd799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:21:37.244583Z",
     "start_time": "2025-11-19T23:21:32.997401Z"
    }
   },
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "log(\"=\" * 80)\n",
    "log(\"Starting train/val CSV generation\")\n",
    "log(\"=\" * 80)\n",
    "\n",
    "# --- 1. Create a mapping from Case Name to Label ---\n",
    "log(\"Building case-to-label mapping...\")\n",
    "case_to_label = {}\n",
    "skipped_tcga = []\n",
    "skipped_unknown = []\n",
    "\n",
    "# Load TCGA labels from Excel\n",
    "tcga_excel_path = 'data/TCGA_BRCA_Filtered/case&annotation_counts_clean.xlsx'\n",
    "if os.path.exists(tcga_excel_path):\n",
    "    tcga_df = pd.read_excel(tcga_excel_path)\n",
    "    log(f\"Loaded TCGA labels from: {tcga_excel_path}\")\n",
    "    tcga_labels = {\n",
    "        str(row['Slide']).strip(): 1 if str(row['Clinical.HER2.status']).strip() == 'Positive' else 0\n",
    "        for _, row in tcga_df.iterrows()\n",
    "        if str(row['Clinical.HER2.status']).strip() in ['Positive', 'Negative']\n",
    "    }\n",
    "    log(f\"Created TCGA label lookup for {len(tcga_labels)} cases.\")\n",
    "else:\n",
    "    tcga_labels = {}\n",
    "    log(f\"Warning: TCGA Excel file not found at {tcga_excel_path}\")\n",
    "\n",
    "# Get all case directories\n",
    "patches_dir = 'outputs/patches'\n",
    "case_dirs = [d for d in glob(os.path.join(patches_dir, '*')) if os.path.isdir(d)]\n",
    "log(f\"Found {len(case_dirs)} case directories to process.\")\n",
    "\n",
    "for case_dir in tqdm(case_dirs, desc='Determining labels for cases'):\n",
    "    case_name = os.path.basename(case_dir)\n",
    "    label = -1\n",
    "\n",
    "    if case_name.startswith('TCGA-'):\n",
    "        tcga_id = case_name.split('.')[0]\n",
    "        if tcga_id in tcga_labels:\n",
    "            label = tcga_labels[tcga_id]\n",
    "        else:\n",
    "            skipped_tcga.append(tcga_id)\n",
    "            continue\n",
    "    elif case_name.startswith(('S', 'O')):\n",
    "        label = 1\n",
    "    elif 'Her2Pos' in case_name or 'Pos' in case_name:\n",
    "        label = 1\n",
    "    elif 'Her2Neg' in case_name or 'Neg' in case_name:\n",
    "        label = 0\n",
    "    else:\n",
    "        skipped_unknown.append(case_name)\n",
    "        continue\n",
    "    \n",
    "    if label != -1:\n",
    "        case_to_label[case_name] = label\n",
    "\n",
    "if skipped_tcga:\n",
    "    log(f\"Skipped {len(skipped_tcga)} TCGA cases not found in Excel: {', '.join(skipped_tcga[:5])}{'...' if len(skipped_tcga) > 5 else ''}\")\n",
    "if skipped_unknown:\n",
    "    log(f\"Skipped {len(skipped_unknown)} cases with unknown labels: {', '.join(skipped_unknown[:5])}{'...' if len(skipped_unknown) > 5 else ''}\")\n",
    "log(f\"Successfully mapped {len(case_to_label)} cases to labels.\")\n",
    "\n",
    "# --- 2. Collect Patches using the Case-to-Label Map ---\n",
    "log(\"Collecting patches from all mapped cases...\")\n",
    "paths, labels, cases = [], [], []\n",
    "for case_name, label in tqdm(case_to_label.items(), desc='Collecting patches'):\n",
    "    patch_files = glob(os.path.join(patches_dir, case_name, f'*.{PATCH_SAVE_FORMAT}'))\n",
    "    paths.extend(patch_files)\n",
    "    labels.extend([label] * len(patch_files))\n",
    "    cases.extend([case_name] * len(patch_files))\n",
    "\n",
    "patches_df = pd.DataFrame({'path': paths, 'label': labels, 'case': cases})\n",
    "log(f\"Total patches collected: {len(patches_df)}\")\n",
    "print(f\"\\nTotal patches found: {len(patches_df)}\")\n",
    "\n",
    "# --- 3. Display Statistics ---\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(patches_df['label'].value_counts())\n",
    "neg_patches = (patches_df['label'] == 0).sum()\n",
    "pos_patches = (patches_df['label'] == 1).sum()\n",
    "log(f\"Label distribution - Negative: {neg_patches}, Positive: {pos_patches}\")\n",
    "\n",
    "cases_by_label = patches_df.groupby('label')['case'].nunique()\n",
    "print(f\"\\nNumber of cases:\")\n",
    "print(f\"Negative cases: {cases_by_label.get(0, 0)}\")\n",
    "print(f\"Positive cases: {cases_by_label.get(1, 0)}\")\n",
    "log(f\"Number of cases - Negative: {cases_by_label.get(0, 0)}, Positive: {cases_by_label.get(1, 0)}\")\n",
    "\n",
    "# --- 4. Split Data by Case to Avoid Leakage ---\n",
    "log(\"Performing train/val split by case...\")\n",
    "from sklearn.model_selection import train_test_split as _tts\n",
    "unique_cases = list(case_to_label.keys())\n",
    "case_labels = list(case_to_label.values())\n",
    "\n",
    "train_cases, val_cases = _tts(\n",
    "    unique_cases,\n",
    "    test_size=0.2,\n",
    "    random_state=42, \n",
    "    stratify=case_labels\n",
    ")\n",
    "\n",
    "train_df = patches_df[patches_df['case'].isin(train_cases)][['path', 'label']]\n",
    "val_df = patches_df[patches_df['case'].isin(val_cases)][['path', 'label']]\n",
    "\n",
    "log(f\"Train patches: {len(train_df)}, Val patches: {len(val_df)}\")\n",
    "log(f\"Train cases: {len(train_cases)}, Val cases: {len(val_cases)}\")\n",
    "print(f\"\\nTrain patches: {len(train_df)}\")\n",
    "print(f\"Val patches: {len(val_df)}\")\n",
    "print(f\"Train cases: {len(train_cases)}\")\n",
    "print(f\"Val cases: {len(val_cases)}\")\n",
    "\n",
    "print(f\"\\nTrain label distribution:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(f\"\\nVal label distribution:\")\n",
    "print(val_df['label'].value_counts())\n",
    "log(f\"Train split - Negative: {(train_df['label']==0).sum()}, Positive: {(train_df['label']==1).sum()}\")\n",
    "log(f\"Val split - Negative: {(val_df['label']==0).sum()}, Positive: {(val_df['label']==1).sum()}\")\n",
    "\n",
    "# --- 5. Save CSV Files ---\n",
    "train_csv_path = 'outputs/patches_index_train.csv'\n",
    "val_csv_path = 'outputs/patches_index_val.csv'\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "val_df.to_csv(val_csv_path, index=False)\n",
    "\n",
    "log(f\"Saved train CSV to: {train_csv_path}\")\n",
    "log(f\"Saved val CSV to: {val_csv_path}\")\n",
    "log(\"Train/val CSV generation completed successfully\")\n",
    "log(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nSaved train CSV to: {train_csv_path}\")\n",
    "print(f\"\\nSaved val CSV to: {val_csv_path}\")\n",
    "\n",
    "print(\"\\nSample from train set:\")\n",
    "display(train_df.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Starting train/val CSV generation\n",
      "================================================================================\n",
      "Building case-to-label mapping...\n",
      "Loaded TCGA labels from: data/TCGA_BRCA_Filtered/case&annotation_counts_clean.xlsx\n",
      "Created TCGA label lookup for 182 cases.\n",
      "Found 451 case directories to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determining labels for cases: 100%|██████████| 451/451 [00:00<00:00, 1665168.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully mapped 451 cases to labels.\n",
      "Collecting patches from all mapped cases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting patches: 100%|██████████| 451/451 [00:01<00:00, 381.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches collected: 1172444\n",
      "\n",
      "Total patches found: 1172444\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "1    621811\n",
      "0    550633\n",
      "Name: count, dtype: int64\n",
      "Label distribution - Negative: 550633, Positive: 621811\n",
      "\n",
      "Number of cases:\n",
      "Negative cases: 187\n",
      "Positive cases: 264\n",
      "Number of cases - Negative: 187, Positive: 264\n",
      "Performing train/val split by case...\n",
      "Train patches: 933109, Val patches: 239335\n",
      "Train cases: 360, Val cases: 91\n",
      "\n",
      "Train patches: 933109\n",
      "Val patches: 239335\n",
      "Train cases: 360\n",
      "Val cases: 91\n",
      "\n",
      "Train label distribution:\n",
      "label\n",
      "1    497173\n",
      "0    435936\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Val label distribution:\n",
      "label\n",
      "1    124638\n",
      "0    114697\n",
      "Name: count, dtype: int64\n",
      "Train split - Negative: 435936, Positive: 497173\n",
      "Val split - Negative: 114697, Positive: 124638\n",
      "Saved train CSV to: outputs/patches_index_train.csv\n",
      "Saved val CSV to: outputs/patches_index_val.csv\n",
      "Train/val CSV generation completed successfully\n",
      "================================================================================\n",
      "\n",
      "Saved train CSV to: outputs/patches_index_train.csv\n",
      "\n",
      "Saved val CSV to: outputs/patches_index_val.csv\n",
      "\n",
      "Sample from train set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                path  label\n",
       "0  outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...      0\n",
       "1  outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...      0\n",
       "2  outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...      0\n",
       "3  outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...      0\n",
       "4  outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outputs/patches/TCGA-AR-A0U4-01Z-00-DX1.DE722D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "f224accb10cd16bb",
   "metadata": {},
   "source": [
    "### Macenko Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e6f84b7e5776b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T23:23:00.126302Z",
     "start_time": "2025-11-19T23:21:37.313698Z"
    }
   },
   "source": [
    "# Helper: detect CSV path column\n",
    "def detect_path_column(df, override=None):\n",
    "    if override:\n",
    "        if override in df.columns:\n",
    "            return override\n",
    "        raise KeyError(f\"CSV_PATH_COLUMN override '{override}' not found in CSV columns\")\n",
    "    candidates = [c for c in df.columns if any(k in c.lower() for k in ('path', 'file', 'img', 'image', 'filename'))]\n",
    "    return candidates[0] if candidates else df.columns[0]\n",
    "\n",
    "\n",
    "# Resolve image path: prefer absolute/relative then recursive search under root\n",
    "def resolve_image_path(raw_path_or_name, root_dir):\n",
    "    if pd.isna(raw_path_or_name):\n",
    "        return None\n",
    "    raw = str(raw_path_or_name)\n",
    "    if os.path.isabs(raw) and os.path.exists(raw):\n",
    "        return raw\n",
    "    cand = os.path.join(root_dir, raw)\n",
    "    if os.path.exists(cand):\n",
    "        return cand\n",
    "    if os.path.exists(raw):\n",
    "        return raw\n",
    "    # fallback: recursive search by basename\n",
    "    base = os.path.basename(raw)\n",
    "    for rt, _, files in os.walk(root_dir):\n",
    "        if base in files:\n",
    "            return os.path.join(rt, base)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Main normalization logic\n",
    "from src.preprocessing.stain_normalization import MacenkoNormalizer\n",
    "\n",
    "PATCHES_ROOT = 'outputs/patches'\n",
    "TRAIN_CSV_PATH = globals().get('train_csv_path', 'outputs/patches_index_train.csv')\n",
    "print('Using train CSV:', TRAIN_CSV_PATH)\n",
    "df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "path_col = detect_path_column(df, override=CSV_PATH_COLUMN)\n",
    "print('Detected path column:', path_col)\n",
    "\n",
    "# Check for existing reference stats\n",
    "ref_stats_path = os.path.join(NORM_OUTPUT_DIR, 'ref_stain_stats.npz')\n",
    "if os.path.exists(ref_stats_path):\n",
    "    print(f\"Found existing reference stain stats: {ref_stats_path}\")\n",
    "    stats = np.load(ref_stats_path)\n",
    "    mean_ref_stain_vectors = stats['mean_stain_vectors']\n",
    "    mean_max_h = stats['mean_max_h']\n",
    "    mean_max_e = stats['mean_max_e']\n",
    "    print(\"Loaded reference stats. Skipping sampling and computation.\")\n",
    "else:\n",
    "    print(\"Reference stain stats not found. Computing from samples.\")\n",
    "    # Collect candidate subfolders recursively under PATCHES_ROOT that contain at least one supported image\n",
    "    candidate_dirs = []\n",
    "    for root, dirs, files in os.walk(PATCHES_ROOT):\n",
    "        # skip the root if it has no images\n",
    "        imgs = [f for f in files if os.path.splitext(f)[1].lower() in IMAGE_EXTS]\n",
    "        if imgs:\n",
    "            candidate_dirs.append(root)\n",
    "\n",
    "    if not candidate_dirs:\n",
    "        raise RuntimeError(f'No image-containing subfolders found under {PATCHES_ROOT}')\n",
    "\n",
    "    num_samples = min(NORM_REFERENCE_SAMPLE_SUBFOLDERS, len(candidate_dirs))\n",
    "    random.seed(42)\n",
    "    sampled_subfolders = random.sample(candidate_dirs, num_samples) if num_samples > 0 else []\n",
    "    print(f\"Sampling {len(sampled_subfolders)} subfolders from {len(candidate_dirs)} available for reference\")\n",
    "\n",
    "    # Instantiate Macenko normalizer (handle fallback to CPU if CuPy not available)\n",
    "    try:\n",
    "        mn_sampling = MacenkoNormalizer(use_gpu=USE_GPU)\n",
    "    except Exception as e:\n",
    "        print('Warning: requested GPU normalization but failed to initialize CuPy or GPU backend; falling back to CPU. Error:', e)\n",
    "        mn_sampling = MacenkoNormalizer(use_gpu=False)\n",
    "\n",
    "    # We'll compute reference stats incrementally to avoid holding many images in memory.\n",
    "    all_stain_vectors = []  # each entry shape (3,2)\n",
    "    all_max_h = []\n",
    "    all_max_e = []\n",
    "    sample_rows = []  # for saving per-file stats\n",
    "    failed = 0\n",
    "    processed_files = 0\n",
    "\n",
    "    for folder in tqdm(sampled_subfolders, desc='Computing reference stats from sampled folders'):\n",
    "        # discover images inside folder recursively\n",
    "        for rt, _, files in os.walk(folder):\n",
    "            for f in files:\n",
    "                if os.path.splitext(f)[1].lower() not in IMAGE_EXTS:\n",
    "                    continue\n",
    "                fp = os.path.join(rt, f)\n",
    "                try:\n",
    "                    with Image.open(fp) as im:\n",
    "                        im = im.convert('RGB')\n",
    "                        arr = np.array(im)\n",
    "                    # compute stain vectors and concentrations for this single image\n",
    "                    try:\n",
    "                        v, conc, _ = mn_sampling._get_stain_vectors_and_concentrations(arr)\n",
    "                    except Exception as e:\n",
    "                        tqdm.write(f'Failed computing stain stats for {fp}: {e}')\n",
    "                        failed += 1\n",
    "                        continue\n",
    "\n",
    "                    # store numeric stats only\n",
    "                    all_stain_vectors.append(v)\n",
    "                    max_h = float(np.percentile(conc[:, 0], mn_sampling.percentiles[1])) if conc.size else 0.0\n",
    "                    max_e = float(np.percentile(conc[:, 1], mn_sampling.percentiles[1])) if conc.size else 0.0\n",
    "                    all_max_h.append(max_h)\n",
    "                    all_max_e.append(max_e)\n",
    "                    sample_rows.append({\n",
    "                        'folder': folder,\n",
    "                        'filepath': fp,\n",
    "                        'max_h': max_h,\n",
    "                        'max_e': max_e,\n",
    "                        'stain_v_00': float(v[0,0]), 'stain_v_01': float(v[0,1]),\n",
    "                        'stain_v_10': float(v[1,0]), 'stain_v_11': float(v[1,1]),\n",
    "                        'stain_v_20': float(v[2,0]), 'stain_v_21': float(v[2,1]),\n",
    "                    })\n",
    "                    processed_files += 1\n",
    "\n",
    "                    # free memory aggressively\n",
    "                    del arr\n",
    "                    del v\n",
    "                    del conc\n",
    "                    gc.collect()\n",
    "                    # free CuPy GPU memory pools if using GPU\n",
    "                    if getattr(mn_sampling, 'use_gpu', False) and getattr(mn_sampling, 'cp', None) is not None:\n",
    "                        try:\n",
    "                            mn_sampling.cp.get_default_memory_pool().free_all_blocks()\n",
    "                            mn_sampling.cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "                        except Exception:\n",
    "                            # older/newer cupy versions may not have pinned pool; ignore failures\n",
    "                            pass\n",
    "                except Exception as e:\n",
    "                    tqdm.write(f'Failed loading sample image {fp}: {e}')\n",
    "                    failed += 1\n",
    "\n",
    "    print(f'Processed {processed_files} sample images from {len(sampled_subfolders)} sampled subfolders; {failed} failures')\n",
    "    if processed_files == 0:\n",
    "        raise RuntimeError('No sample images found to compute reference stain profile')\n",
    "\n",
    "    # Combine per-image stain vectors into mean reference stain vectors\n",
    "    mean_ref_stain_vectors = np.mean(np.stack(all_stain_vectors, axis=0), axis=0)\n",
    "    mean_max_h = float(np.mean(all_max_h))\n",
    "    mean_max_e = float(np.mean(all_max_e))\n",
    "    print('Computed mean stain vectors and concentrations: shapes:', mean_ref_stain_vectors.shape)\n",
    "\n",
    "    # Save reference stats and per-sample CSV\n",
    "    Path(NORM_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    np.savez(ref_stats_path, mean_stain_vectors=mean_ref_stain_vectors, mean_max_h=mean_max_h, mean_max_e=mean_max_e)\n",
    "    print('Saved reference stats to', ref_stats_path)\n",
    "\n",
    "    # save per-sample stats\n",
    "    sample_stats_csv = os.path.join(NORM_OUTPUT_DIR, 'ref_stain_samples.csv')\n",
    "    try:\n",
    "        pd.DataFrame(sample_rows).to_csv(sample_stats_csv, index=False)\n",
    "        print('Saved per-sample stain stats to', sample_stats_csv)\n",
    "    except Exception as e:\n",
    "        print('Warning: failed saving per-sample stats CSV:', e)\n",
    "\n",
    "# Instantiate Macenko normalizer for the main normalization task\n",
    "try:\n",
    "    mn = MacenkoNormalizer(use_gpu=USE_GPU)\n",
    "except Exception as e:\n",
    "    print('Warning: requested GPU normalization but failed to initialize CuPy or GPU backend; falling back to CPU. Error:', e)\n",
    "    mn = MacenkoNormalizer(use_gpu=False)\n",
    "\n",
    "# Normalize images referenced by train CSV and save results mirroring structure under NORM_OUTPUT_DIR\n",
    "import concurrent.futures\n",
    "\n",
    "def normalize_image_worker(args):\n",
    "    \"\"\"Worker function to normalize a single image.\"\"\"\n",
    "    row_dict, path_col, mn_use_gpu, mean_ref_stain_vectors, mean_max_h, mean_max_e = args\n",
    "\n",
    "    # It's crucial to instantiate the normalizer inside the worker\n",
    "    # if using GPU to ensure correct context initialization per-process.\n",
    "    try:\n",
    "        mn_worker = MacenkoNormalizer(use_gpu=mn_use_gpu)\n",
    "    except Exception as e:\n",
    "        # Fallback or log if GPU init fails in worker\n",
    "        mn_worker = MacenkoNormalizer(use_gpu=False)\n",
    "\n",
    "    raw = row_dict[path_col]\n",
    "    src = resolve_image_path(raw, PATCHES_ROOT)\n",
    "    if not src:\n",
    "        return None, f\"Source not resolved for {raw}\"\n",
    "\n",
    "    try:\n",
    "        with Image.open(src) as im:\n",
    "            im = im.convert('RGB')\n",
    "            arr = np.array(im)\n",
    "\n",
    "        out_arr = mn_worker.normalize(\n",
    "            arr,\n",
    "            mean_ref_stain_vectors=mean_ref_stain_vectors,\n",
    "            mean_ref_max_concentrations_tuple=(mean_max_h, mean_max_e)\n",
    "        )\n",
    "\n",
    "        rel = os.path.relpath(src, PATCHES_ROOT)\n",
    "        dst = os.path.join(NORM_OUTPUT_DIR, rel)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        Image.fromarray(out_arr).save(dst)\n",
    "\n",
    "        new_row = dict(row_dict)\n",
    "        new_row[path_col] = dst\n",
    "        return new_row, None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, f\"Failed normalizing {src}: {e}\"\n",
    "\n",
    "# Prepare arguments for the workers\n",
    "rows_to_process = [row.to_dict() for _, row in df.iterrows()]\n",
    "worker_args = [\n",
    "    (row_dict, path_col, USE_GPU, mean_ref_stain_vectors, mean_max_h, mean_max_e)\n",
    "    for row_dict in rows_to_process\n",
    "]\n",
    "\n",
    "out_rows = []\n",
    "errors = 0\n",
    "out_csv = 'outputs/patches_index_train_norm.csv'\n",
    "\n",
    "# Use ProcessPoolExecutor for parallel processing\n",
    "# Using max_workers=None will default to the number of processors on the machine.\n",
    "# Adjust if you want to limit CPU usage.\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    # Using tqdm to show progress with multiprocessing\n",
    "    results = list(tqdm(executor.map(normalize_image_worker, worker_args), total=len(rows_to_process), desc=\"Normalizing\"))\n",
    "\n",
    "for new_row, error_msg in results:\n",
    "    if error_msg:\n",
    "        errors += 1\n",
    "        tqdm.write(error_msg)\n",
    "    if new_row:\n",
    "        out_rows.append(new_row)\n",
    "\n",
    "if out_rows:\n",
    "    pd.DataFrame(out_rows).to_csv(out_csv, index=False)\n",
    "    print('Saved normalized CSV to', out_csv)\n",
    "else:\n",
    "    print('No normalized rows to save')\n",
    "\n",
    "\n",
    "print('Normalization complete. Errors:', errors)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train CSV: outputs/patches_index_train.csv\n",
      "Detected path column: path\n",
      "Found existing reference stain stats: /media/thanakornbuath/patch/norm/ref_stain_stats.npz\n",
      "Loaded reference stats. Skipping sampling and computation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing:   5%|▌         | 47804/933109 [00:45<13:48, 1069.10it/s]Process ForkProcess-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thanakornbuath/anaconda3/envs/her2-class/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/thanakornbuath/anaconda3/envs/her2-class/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/thanakornbuath/anaconda3/envs/her2-class/lib/python3.12/concurrent/futures/process.py\", line 246, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/thanakornbuath/anaconda3/envs/her2-class/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/thanakornbuath/anaconda3/envs/her2-class/lib/python3.12/threading.py\", line 1052, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/thanakornbuath/anaconda3/envs/her2-class/lib/python3.12/concurrent/futures/process.py\", line 344, in run\n",
      "    self.terminate_broken(cause)\n",
      "  File \"/home/thanakornbuath/anaconda3/envs/her2-class/lib/python3.12/concurrent/futures/process.py\", line 492, in terminate_broken\n",
      "    work_item.future.set_exception(bpe)\n",
      "  File \"/home/thanakornbuath/anaconda3/envs/her2-class/lib/python3.12/concurrent/futures/_base.py\", line 559, in set_exception\n",
      "    raise InvalidStateError('{}: {!r}'.format(self._state, self))\n",
      "concurrent.futures._base.InvalidStateError: CANCELLED: <Future at 0x741a3a5e2900 state=cancelled>\n",
      "KeyboardInterrupt\n",
      "Normalizing:   5%|▌         | 47842/933109 [00:45<14:06, 1045.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 225\u001B[39m\n\u001B[32m    220\u001B[39m \u001B[38;5;66;03m# Use ProcessPoolExecutor for parallel processing\u001B[39;00m\n\u001B[32m    221\u001B[39m \u001B[38;5;66;03m# Using max_workers=None will default to the number of processors on the machine.\u001B[39;00m\n\u001B[32m    222\u001B[39m \u001B[38;5;66;03m# Adjust if you want to limit CPU usage.\u001B[39;00m\n\u001B[32m    223\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m concurrent.futures.ProcessPoolExecutor() \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[32m    224\u001B[39m     \u001B[38;5;66;03m# Using tqdm to show progress with multiprocessing\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m225\u001B[39m     results = \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexecutor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnormalize_image_worker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mworker_args\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrows_to_process\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mNormalizing\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    227\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m new_row, error_msg \u001B[38;5;129;01min\u001B[39;00m results:\n\u001B[32m    228\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m error_msg:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/her2-class/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[32m   1182\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[32m   1183\u001B[39m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[32m   1184\u001B[39m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/her2-class/lib/python3.12/concurrent/futures/process.py:608\u001B[39m, in \u001B[36m_chain_from_iterable_of_lists\u001B[39m\u001B[34m(iterable)\u001B[39m\n\u001B[32m    602\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_chain_from_iterable_of_lists\u001B[39m(iterable):\n\u001B[32m    603\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    604\u001B[39m \u001B[33;03m    Specialized implementation of itertools.chain.from_iterable.\u001B[39;00m\n\u001B[32m    605\u001B[39m \u001B[33;03m    Each item in *iterable* should be a list.  This function is\u001B[39;00m\n\u001B[32m    606\u001B[39m \u001B[33;03m    careful not to keep references to yielded objects.\u001B[39;00m\n\u001B[32m    607\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m608\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43melement\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    609\u001B[39m \u001B[43m        \u001B[49m\u001B[43melement\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreverse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    610\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mwhile\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43melement\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/her2-class/lib/python3.12/concurrent/futures/_base.py:619\u001B[39m, in \u001B[36mExecutor.map.<locals>.result_iterator\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    616\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m fs:\n\u001B[32m    617\u001B[39m     \u001B[38;5;66;03m# Careful not to keep a reference to the popped future\u001B[39;00m\n\u001B[32m    618\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m619\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43m_result_or_cancel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    620\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    621\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/her2-class/lib/python3.12/concurrent/futures/_base.py:317\u001B[39m, in \u001B[36m_result_or_cancel\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    315\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    316\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m317\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    318\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    319\u001B[39m         fut.cancel()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/her2-class/lib/python3.12/concurrent/futures/_base.py:451\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m    449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.__get_result()\n\u001B[32m--> \u001B[39m\u001B[32m451\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_condition\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[32m    454\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/her2-class/lib/python3.12/threading.py:334\u001B[39m, in \u001B[36mCondition.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    332\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[32m    333\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m334\u001B[39m         \u001B[43mwaiter\u001B[49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    335\u001B[39m         gotit = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    336\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "cd517e40628c1627",
   "metadata": {},
   "source": [
    "## Training Phase 1 - ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "id": "43b5d1d3df6ebd35",
   "metadata": {},
   "source": [
    "# Phase 1 — Train ResNet-50 (module)\n",
    "# Use normalized CSV for training if requested and available\n",
    "train_csv_for_training = train_csv_path\n",
    "_norm_csv_default = 'outputs/patches_index_train_norm.csv'\n",
    "if USE_NORMALIZED_FOR_TRAINING and os.path.exists(_norm_csv_default):\n",
    "    train_csv_for_training = _norm_csv_default\n",
    "    log(f\"Using normalized train CSV for training: {train_csv_for_training}\")\n",
    "else:\n",
    "    if USE_NORMALIZED_FOR_TRAINING:\n",
    "        log(f\"Requested normalized training but file not found: {_norm_csv_default}. Falling back to original train_csv.\")\n",
    "\n",
    "CFG = {\n",
    "    'train_csv': train_csv_for_training,\n",
    "    'val_csv': val_csv_path,\n",
    "    'output_dir': 'outputs/phase1',\n",
    "    'pretrained': True,\n",
    "    'input_size': PATCH_SIZE,\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 4,\n",
    "    'epochs': 10,\n",
    "    'lr': 1e-5,\n",
    "    'weight_decay': 1e-4,\n",
    "    'label_col': 'label',\n",
    "    'path_col': 'path',\n",
    "    'save_best_by': 'auc',\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "results = train_phase1(CFG)\n",
    "print('Best model:', results['best_model_path'])\n",
    "print('Logs dir:', results['logs_dir'])"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
